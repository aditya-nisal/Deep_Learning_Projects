{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bnTgsxhGjCvG",
        "outputId": "e06e6fce-8082-4686-9349-3575a702867b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "faces.shape: (7500, 48, 48)\n",
            "ages.shape: (7500,)\n",
            "(5500, 48, 48, 3)\n",
            "(5500,)\n",
            "(500, 48, 48, 3)\n",
            "(500,)\n",
            "(1500, 48, 48, 3)\n",
            "(1500,)\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow.keras.applications.resnet50 import ResNet50\n",
        "from tensorflow.keras.layers import GlobalAveragePooling2D, Dense, Flatten\n",
        "from tensorflow.keras.models import Model\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "\n",
        "# Load the data into NumPy arrays\n",
        "faces_greyscale = np.load('/content/faces.npy')\n",
        "print(\"faces.shape:\", faces_greyscale.shape)\n",
        "age_labels = np.load('/content/ages.npy')\n",
        "print(\"ages.shape:\", age_labels.shape)\n",
        "# matrix = np.array([faces_greyscale, age_labels])\n",
        "\n",
        "# # Select 80% of numbers randomly using np.random.choice\n",
        "selected_numbers = np.random.choice(faces_greyscale.shape[0], size=int(0.8*(faces_greyscale.shape[0])), replace=False)\n",
        "all_indices = np.arange(faces_greyscale.shape[0])\n",
        "test_indices = np.setdiff1d(all_indices, selected_numbers)\n",
        "\n",
        "faces_greyscale_trainval = faces_greyscale[selected_numbers]\n",
        "age_labels_trainval = age_labels[selected_numbers]\n",
        "# print(faces_greyscale_trainval.shape)\n",
        "# print(age_labels_trainval.shape)\n",
        "faces_rgb_trainval = np.repeat(faces_greyscale_trainval[..., np.newaxis], 3, axis = -1)\n",
        "faces_rgb_trainval = faces_rgb_trainval.astype('float32') / 255.0\n",
        "\n",
        "#Training\n",
        "faces_rgb_train = faces_rgb_trainval[:5500]\n",
        "age_labels_train = age_labels_trainval[:5500]\n",
        "\n",
        "#Validation\n",
        "faces_rgb_val = faces_rgb_trainval[5500:]\n",
        "age_labels_val = age_labels_trainval[5500:]\n",
        "\n",
        "#Test\n",
        "faces_greyscale_test = faces_greyscale[test_indices]\n",
        "age_labels_test = age_labels[test_indices]\n",
        "faces_rgb_test = np.repeat(faces_greyscale_test[..., np.newaxis], 3, axis = -1)\n",
        "faces_rgb_test = faces_rgb_test.astype('float32') / 255.0\n",
        "\n",
        "print(faces_rgb_train.shape)\n",
        "print(age_labels_train.shape)\n",
        "print(faces_rgb_val.shape)\n",
        "print(age_labels_val.shape)\n",
        "print(faces_rgb_test.shape)\n",
        "print(age_labels_test.shape)\n",
        "# Creating a TensorFlow dataset from the NumPy arrays\n",
        "dataset = tf.data.Dataset.from_tensor_slices((faces_rgb_trainval, age_labels_trainval))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 466
        },
        "id": "tQn_UJLqp1cg",
        "outputId": "b43ea128-99b4-4436-85dc-64f4cfbd2650"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "data: (6000, 48, 48, 3) labels: (6000,)\n",
            "Age of this person is: 46\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "print(\"data:\", faces_rgb_trainval.shape, \"labels:\", age_labels_trainval.shape)\n",
        "plt.imshow(faces_rgb_train[1])\n",
        "print(\"Age of this person is:\", age_labels_train[1].astype('int'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MXi-7pVg5r0W",
        "outputId": "061f8391-8337-43e8-b94e-3f677a0e1fec"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(5500, 48, 48, 3)\n",
            "(5500,)\n",
            "(1500,)\n"
          ]
        }
      ],
      "source": [
        "# input_shape = (224, 224, 3)\n",
        "# num_classes = 1\n",
        "\n",
        "# train_images = tf.image.resize(faces_rgb_train, (input_shape[0], input_shape[1]))\n",
        "# val_images = tf.image.resize(faces_rgb_val, (input_shape[0], input_shape[1]))\n",
        "# test_images = tf.image.resize(faces_rgb_test, (input_shape[0], input_shape[1]))\n",
        "\n",
        "age_labels_train = age_labels_train.astype('float32')\n",
        "age_labels_val = age_labels_val.astype('float32')\n",
        "age_labels_test = age_labels_test.astype('float32')\n",
        "print(faces_rgb_train.shape)\n",
        "print(age_labels_train.shape)\n",
        "print(age_labels_test.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I401QPrO65qe",
        "outputId": "b16ef563-7cb6-4d95-bef8-84b11c98e80c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30\n",
            "170/172 [============================>.] - ETA: 0s - loss: 316.4487 - mse: 316.4487\n",
            "Epoch 1: val_loss improved from inf to 230.94365, saving model to final_model.weights.best.hdf5\n",
            "172/172 [==============================] - 9s 27ms/step - loss: 315.1142 - mse: 315.1142 - val_loss: 230.9436 - val_mse: 230.9436\n",
            "Epoch 2/30\n",
            "171/172 [============================>.] - ETA: 0s - loss: 219.2391 - mse: 219.2391\n",
            "Epoch 2: val_loss improved from 230.94365 to 223.43481, saving model to final_model.weights.best.hdf5\n",
            "172/172 [==============================] - 4s 21ms/step - loss: 219.3547 - mse: 219.3547 - val_loss: 223.4348 - val_mse: 223.4348\n",
            "Epoch 3/30\n",
            "171/172 [============================>.] - ETA: 0s - loss: 213.1149 - mse: 213.1149\n",
            "Epoch 3: val_loss did not improve from 223.43481\n",
            "172/172 [==============================] - 3s 20ms/step - loss: 212.8770 - mse: 212.8770 - val_loss: 224.1610 - val_mse: 224.1610\n",
            "Epoch 4/30\n",
            "170/172 [============================>.] - ETA: 0s - loss: 208.9355 - mse: 208.9355\n",
            "Epoch 4: val_loss improved from 223.43481 to 215.19318, saving model to final_model.weights.best.hdf5\n",
            "172/172 [==============================] - 4s 21ms/step - loss: 209.1920 - mse: 209.1920 - val_loss: 215.1932 - val_mse: 215.1932\n",
            "Epoch 5/30\n",
            "171/172 [============================>.] - ETA: 0s - loss: 204.6415 - mse: 204.6415\n",
            "Epoch 5: val_loss improved from 215.19318 to 208.95747, saving model to final_model.weights.best.hdf5\n",
            "172/172 [==============================] - 4s 21ms/step - loss: 204.3024 - mse: 204.3024 - val_loss: 208.9575 - val_mse: 208.9575\n",
            "Epoch 6/30\n",
            "171/172 [============================>.] - ETA: 0s - loss: 199.9973 - mse: 199.9973\n",
            "Epoch 6: val_loss improved from 208.95747 to 206.61728, saving model to final_model.weights.best.hdf5\n",
            "172/172 [==============================] - 4s 23ms/step - loss: 199.7521 - mse: 199.7521 - val_loss: 206.6173 - val_mse: 206.6173\n",
            "Epoch 7/30\n",
            "172/172 [==============================] - ETA: 0s - loss: 198.0234 - mse: 198.0234\n",
            "Epoch 7: val_loss improved from 206.61728 to 204.01535, saving model to final_model.weights.best.hdf5\n",
            "172/172 [==============================] - 4s 21ms/step - loss: 198.0234 - mse: 198.0234 - val_loss: 204.0154 - val_mse: 204.0154\n",
            "Epoch 8/30\n",
            "169/172 [============================>.] - ETA: 0s - loss: 195.7589 - mse: 195.7589\n",
            "Epoch 8: val_loss did not improve from 204.01535\n",
            "172/172 [==============================] - 3s 18ms/step - loss: 196.0714 - mse: 196.0714 - val_loss: 210.3815 - val_mse: 210.3815\n",
            "Epoch 9/30\n",
            "172/172 [==============================] - ETA: 0s - loss: 195.1278 - mse: 195.1278\n",
            "Epoch 9: val_loss did not improve from 204.01535\n",
            "172/172 [==============================] - 3s 18ms/step - loss: 195.1278 - mse: 195.1278 - val_loss: 222.5622 - val_mse: 222.5622\n",
            "Epoch 10/30\n",
            "170/172 [============================>.] - ETA: 0s - loss: 192.4627 - mse: 192.4627\n",
            "Epoch 10: val_loss improved from 204.01535 to 200.36147, saving model to final_model.weights.best.hdf5\n",
            "172/172 [==============================] - 4s 25ms/step - loss: 192.8060 - mse: 192.8060 - val_loss: 200.3615 - val_mse: 200.3615\n",
            "Epoch 11/30\n",
            "171/172 [============================>.] - ETA: 0s - loss: 192.0828 - mse: 192.0828\n",
            "Epoch 11: val_loss improved from 200.36147 to 198.82640, saving model to final_model.weights.best.hdf5\n",
            "172/172 [==============================] - 4s 21ms/step - loss: 191.7423 - mse: 191.7423 - val_loss: 198.8264 - val_mse: 198.8264\n",
            "Epoch 12/30\n",
            "171/172 [============================>.] - ETA: 0s - loss: 188.1162 - mse: 188.1162\n",
            "Epoch 12: val_loss improved from 198.82640 to 197.73607, saving model to final_model.weights.best.hdf5\n",
            "172/172 [==============================] - 4s 21ms/step - loss: 189.2447 - mse: 189.2447 - val_loss: 197.7361 - val_mse: 197.7361\n",
            "Epoch 13/30\n",
            "171/172 [============================>.] - ETA: 0s - loss: 190.9550 - mse: 190.9550\n",
            "Epoch 13: val_loss did not improve from 197.73607\n",
            "172/172 [==============================] - 4s 21ms/step - loss: 190.8125 - mse: 190.8125 - val_loss: 198.2378 - val_mse: 198.2378\n",
            "Epoch 14/30\n",
            "171/172 [============================>.] - ETA: 0s - loss: 187.5096 - mse: 187.5096\n",
            "Epoch 14: val_loss did not improve from 197.73607\n",
            "172/172 [==============================] - 3s 18ms/step - loss: 187.8819 - mse: 187.8819 - val_loss: 197.8581 - val_mse: 197.8581\n",
            "Epoch 15/30\n",
            "172/172 [==============================] - ETA: 0s - loss: 187.4577 - mse: 187.4577\n",
            "Epoch 15: val_loss did not improve from 197.73607\n",
            "172/172 [==============================] - 3s 18ms/step - loss: 187.4577 - mse: 187.4577 - val_loss: 200.9349 - val_mse: 200.9349\n",
            "Epoch 16/30\n",
            "169/172 [============================>.] - ETA: 0s - loss: 187.8938 - mse: 187.8938\n",
            "Epoch 16: val_loss improved from 197.73607 to 194.82982, saving model to final_model.weights.best.hdf5\n",
            "172/172 [==============================] - 4s 21ms/step - loss: 187.5965 - mse: 187.5965 - val_loss: 194.8298 - val_mse: 194.8298\n",
            "Epoch 17/30\n",
            "169/172 [============================>.] - ETA: 0s - loss: 184.0607 - mse: 184.0607\n",
            "Epoch 17: val_loss did not improve from 194.82982\n",
            "172/172 [==============================] - 3s 20ms/step - loss: 184.0161 - mse: 184.0161 - val_loss: 194.8711 - val_mse: 194.8711\n",
            "Epoch 18/30\n",
            "170/172 [============================>.] - ETA: 0s - loss: 184.2182 - mse: 184.2182\n",
            "Epoch 18: val_loss did not improve from 194.82982\n",
            "172/172 [==============================] - 3s 19ms/step - loss: 184.6190 - mse: 184.6190 - val_loss: 205.0432 - val_mse: 205.0432\n",
            "Epoch 19/30\n",
            "172/172 [==============================] - ETA: 0s - loss: 185.7414 - mse: 185.7414\n",
            "Epoch 19: val_loss improved from 194.82982 to 193.21545, saving model to final_model.weights.best.hdf5\n",
            "172/172 [==============================] - 4s 21ms/step - loss: 185.7414 - mse: 185.7414 - val_loss: 193.2155 - val_mse: 193.2155\n",
            "Epoch 20/30\n",
            "170/172 [============================>.] - ETA: 0s - loss: 183.3222 - mse: 183.3222\n",
            "Epoch 20: val_loss did not improve from 193.21545\n",
            "172/172 [==============================] - 3s 19ms/step - loss: 183.6099 - mse: 183.6099 - val_loss: 194.8198 - val_mse: 194.8198\n",
            "Epoch 21/30\n",
            "171/172 [============================>.] - ETA: 0s - loss: 183.7622 - mse: 183.7622\n",
            "Epoch 21: val_loss did not improve from 193.21545\n",
            "172/172 [==============================] - 3s 19ms/step - loss: 183.8198 - mse: 183.8198 - val_loss: 202.3373 - val_mse: 202.3373\n",
            "Epoch 22/30\n",
            "170/172 [============================>.] - ETA: 0s - loss: 182.7721 - mse: 182.7721\n",
            "Epoch 22: val_loss did not improve from 193.21545\n",
            "172/172 [==============================] - 3s 18ms/step - loss: 183.0577 - mse: 183.0577 - val_loss: 194.4586 - val_mse: 194.4586\n",
            "Epoch 23/30\n",
            "171/172 [============================>.] - ETA: 0s - loss: 179.8648 - mse: 179.8648\n",
            "Epoch 23: val_loss did not improve from 193.21545\n",
            "172/172 [==============================] - 3s 18ms/step - loss: 179.8958 - mse: 179.8958 - val_loss: 220.3992 - val_mse: 220.3992\n",
            "Epoch 24/30\n",
            "172/172 [==============================] - ETA: 0s - loss: 182.1721 - mse: 182.1721\n",
            "Epoch 24: val_loss did not improve from 193.21545\n",
            "172/172 [==============================] - 3s 20ms/step - loss: 182.1721 - mse: 182.1721 - val_loss: 193.6981 - val_mse: 193.6981\n",
            "Epoch 25/30\n",
            "172/172 [==============================] - ETA: 0s - loss: 180.3846 - mse: 180.3846\n",
            "Epoch 25: val_loss did not improve from 193.21545\n",
            "172/172 [==============================] - 3s 18ms/step - loss: 180.3846 - mse: 180.3846 - val_loss: 194.0184 - val_mse: 194.0184\n",
            "Epoch 26/30\n",
            "170/172 [============================>.] - ETA: 0s - loss: 178.0973 - mse: 178.0973\n",
            "Epoch 26: val_loss improved from 193.21545 to 191.14980, saving model to final_model.weights.best.hdf5\n",
            "172/172 [==============================] - 4s 22ms/step - loss: 179.1857 - mse: 179.1857 - val_loss: 191.1498 - val_mse: 191.1498\n",
            "Epoch 27/30\n",
            "171/172 [============================>.] - ETA: 0s - loss: 179.4552 - mse: 179.4552\n",
            "Epoch 27: val_loss did not improve from 191.14980\n",
            "172/172 [==============================] - 3s 18ms/step - loss: 179.5190 - mse: 179.5190 - val_loss: 191.9236 - val_mse: 191.9236\n",
            "Epoch 28/30\n",
            "169/172 [============================>.] - ETA: 0s - loss: 178.4414 - mse: 178.4414\n",
            "Epoch 28: val_loss did not improve from 191.14980\n",
            "172/172 [==============================] - 4s 21ms/step - loss: 177.7691 - mse: 177.7691 - val_loss: 194.5526 - val_mse: 194.5526\n",
            "Epoch 29/30\n",
            "172/172 [==============================] - ETA: 0s - loss: 180.9464 - mse: 180.9464\n",
            "Epoch 29: val_loss improved from 191.14980 to 190.81418, saving model to final_model.weights.best.hdf5\n",
            "172/172 [==============================] - 4s 21ms/step - loss: 180.9464 - mse: 180.9464 - val_loss: 190.8142 - val_mse: 190.8142\n",
            "Epoch 30/30\n",
            "172/172 [==============================] - ETA: 0s - loss: 177.7907 - mse: 177.7907\n",
            "Epoch 30: val_loss did not improve from 190.81418\n",
            "172/172 [==============================] - 3s 18ms/step - loss: 177.7907 - mse: 177.7907 - val_loss: 193.7686 - val_mse: 193.7686\n",
            "47/47 [==============================] - 1s 20ms/step - loss: 164.2970 - mse: 164.2970\n",
            "Test RMSE =  12.817837231527998\n"
          ]
        }
      ],
      "source": [
        "#Creating and training the Resnet50 model\n",
        "\n",
        "#Loading the ResNet50 model from tensorflow\n",
        "resnet_model = ResNet50(weights='imagenet', include_top = False, input_shape = (48,48,3))  \n",
        "#Imagenet-using pretrainied weights, include_top-removing the last FC network to output a real number hence False\n",
        "\n",
        "#Freexing the layers\n",
        "for layer in resnet_model.layers:\n",
        "  layer.trainable = False\n",
        "\n",
        "#Replacing the last layer with a new dense layer to get a real number as an output\n",
        "# x = Dense(1, activation='linear')(resnet_model.layers[-2].output)\n",
        "# x = resnet_model.output\n",
        "# x = GlobalAveragePooling2D()(x)\n",
        "# x = Dense(256,activation='relu')(x)\n",
        "# x = Dense(128,activation='relu')(x)\n",
        "# x = Dense(1, activation='linear')(x)\n",
        "x=Flatten()(resnet_model.output)\n",
        "x=Dense(256,activation='relu')(x)\n",
        "x=Dense(128,activation='relu')(x)\n",
        "x = Dense(1)(x)\n",
        "\n",
        "#Creating a new model\n",
        "model = Model(inputs=resnet_model.input, outputs=x)\n",
        "\n",
        "#Compiling the model\n",
        "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.00025), loss='mse', metrics=['mse'])\n",
        "checkpointer = ModelCheckpoint(filepath='final_model.weights.best.hdf5', verbose=1, save_best_only=True)\n",
        "#Training the model\n",
        "history = model.fit(faces_rgb_train, age_labels_train, epochs = 30, batch_size = 32, validation_data=(faces_rgb_val, age_labels_val), callbacks=[checkpointer])\n",
        "\n",
        "results = model.evaluate(faces_rgb_test, age_labels_test, batch_size=32)\n",
        "print(\"Test RMSE = \", np.sqrt(results[1]))"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}